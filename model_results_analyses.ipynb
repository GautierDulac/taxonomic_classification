{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Global-parameters\" data-toc-modified-id=\"Global-parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Global parameters</a></span></li><li><span><a href=\"#Family-from-Genus\" data-toc-modified-id=\"Family-from-Genus-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Family from Genus</a></span></li><li><span><a href=\"#With-a-NB-model\" data-toc-modified-id=\"With-a-NB-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>With a NB model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Treat-results\" data-toc-modified-id=\"Treat-results-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Treat results</a></span></li></ul></li><li><span><a href=\"#With-a-CNN-model\" data-toc-modified-id=\"With-a-CNN-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>With a CNN model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Parameters-to-load\" data-toc-modified-id=\"Parameters-to-load-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Parameters to load</a></span></li><li><span><a href=\"#Loading-the-model\" data-toc-modified-id=\"Loading-the-model-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Loading the model</a></span></li><li><span><a href=\"#Processing-Data\" data-toc-modified-id=\"Processing-Data-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Processing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#On-the-train\" data-toc-modified-id=\"On-the-train-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>On the train</a></span></li><li><span><a href=\"#On-the-test\" data-toc-modified-id=\"On-the-test-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>On the test</a></span></li><li><span><a href=\"#Comparisons\" data-toc-modified-id=\"Comparisons-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>Comparisons</a></span></li></ul></li><li><span><a href=\"#Comparing-one-rank-above\" data-toc-modified-id=\"Comparing-one-rank-above-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Comparing one rank above</a></span><ul class=\"toc-item\"><li><span><a href=\"#Retrieving--the-new-predictions-/-real-classes\" data-toc-modified-id=\"Retrieving--the-new-predictions-/-real-classes-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Retrieving  the new predictions / real classes</a></span></li><li><span><a href=\"#Accuracy-Analyses\" data-toc-modified-id=\"Accuracy-Analyses-5.4.2\"><span class=\"toc-item-num\">5.4.2&nbsp;&nbsp;</span>Accuracy Analyses</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.loading_model_data import main_loading_model_data\n",
    "from models.cnn_preprocessing import main_preprocessing_cnn, get_homogenous_vector\n",
    "from models.cnn_model import classifier_GD_2_ACM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_origin = 'DairyDB'\n",
    "primers_origin = 'Chaudhary'\n",
    "taxonomy_level = 5\n",
    "selected_primer = 'V4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family from Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('data\\\\dairydb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = list(db['family'])\n",
    "genuses = list(db['genus'])\n",
    "orders = list(db['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genus_to_family = {}\n",
    "dict_genus_to_order = {}\n",
    "for index, genus in enumerate(genuses):\n",
    "    family = families[index]\n",
    "    if genus in dict_genus_to_family.keys() and family != dict_genus_to_family[genus]:\n",
    "        raise ValueError('Two Families for a same Genus')\n",
    "    elif genus in dict_genus_to_family.keys():\n",
    "        pass\n",
    "    else:\n",
    "        dict_genus_to_family[genus] = family\n",
    "    order = orders[index]\n",
    "    if genus in dict_genus_to_order.keys() and order != dict_genus_to_order[genus]:\n",
    "        raise ValueError('Two Orders for a same Genus')\n",
    "    elif genus in dict_genus_to_order.keys():\n",
    "        pass\n",
    "    else:\n",
    "        dict_genus_to_order[genus] = order    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_family_to_id = {}\n",
    "dict_order_to_id = {}\n",
    "for index, family in enumerate(np.unique(list(dict_genus_to_family.values()))):\n",
    "    dict_family_to_id[family] = index\n",
    "for index, order in enumerate(np.unique(list(dict_genus_to_order.values()))):\n",
    "    dict_order_to_id[order] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_preprocessing_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3bc912531228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0msequence_origin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprimers_origin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprimers_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mselected_primer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselected_primer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtaxonomy_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtaxonomy_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_preprocessing_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=sequence_origin, \n",
    "        primers_origin=primers_origin,\n",
    "        selected_primer=selected_primer, \n",
    "        taxonomy_level=taxonomy_level,\n",
    "        max_size=300,\n",
    "        k_mer=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.naive_bayes_k import ETL_NB_k_mer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "X_train, X_test, y_train, y_test = ETL_NB_k_mer(k=k,\n",
    "                                                sequence_origin=sequence_origin,\n",
    "                                                primers_origin=primers_origin,\n",
    "                                                taxonomy_level=taxonomy_level,\n",
    "                                                selected_primer=selected_primer)\n",
    "GNB = GaussianNB()\n",
    "y_pred = GNB.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_test_results = y_pred\n",
    "chosen_order_test_results = [dict_genus_to_order[pred] for pred in y_pred]\n",
    "chosen_family_test_results = [dict_genus_to_family[pred] for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_class_test_results = np.array(y_test.genus)\n",
    "real_order_test_results = [dict_genus_to_order[c] for c in real_genus_test_results]\n",
    "real_family_test_results = [dict_genus_to_family[c] for c in real_genus_test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_train_results = GNB.predict(X_train)\n",
    "chosen_order_train_results = [dict_genus_to_order[c] for c in chosen_genus_train_results]\n",
    "chosen_family_train_results = [dict_genus_to_family[c] for c in chosen_genus_train_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_class_train_results = np.array(y_train.genus)\n",
    "real_order_train_results = [dict_genus_to_order[c] for c in real_genus_train_results]\n",
    "real_family_train_results = [dict_genus_to_family[c] for c in real_genus_train_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "absolute_train_errors = [chosen_class_train_results[i] != real_class_train_results[i] for i in range(len(real_class_train_results))]\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_class_train_results))) * 100))\n",
    "absolute_train_errors = [chosen_family_train_results[i] != real_family_train_results[i] for i in range(len(real_family_train_results))]\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_family_train_results))) * 100))\n",
    "absolute_train_errors = [chosen_order_train_results[i] != real_order_train_results[i] for i in range(len(real_order_train_results))]\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_order_train_results))) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_test_errors = [chosen_class_test_results[i] != real_class_test_results[i] for i in range(len(real_class_test_results))]\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_class_test_results))) * 100))\n",
    "absolute_test_errors = [chosen_family_test_results[i] != real_family_test_results[i] for i in range(len(real_family_test_results))]\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_family_test_results))) * 100))\n",
    "absolute_test_errors = [chosen_order_test_results[i] != real_order_test_results[i] for i in range(len(real_order_test_results))]\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_order_test_results))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.random_forest import random_forest_k_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/personal_project/taxonomic_classification/models/random_forest.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  y_pred = RF.fit(X_train, y_train).predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 11.7 s, total: 3min 17s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "RF, test_size, main_class_prop, accuracy = random_forest_k_default(k=5,sequence_origin='DairyDB', \n",
    "                                                               primers_origin='Chaudhary', \n",
    "                                                               taxonomy_level=5,\n",
    "                                                               selected_primer='V4', \n",
    "                                                               max_depth=25,\n",
    "                                                               n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.naive_bayes_k import ETL_NB_k_mer\n",
    "\n",
    "k = 5\n",
    "X_train, X_test, y_train, y_test = ETL_NB_k_mer(k=k,\n",
    "                                                sequence_origin=sequence_origin,\n",
    "                                                primers_origin=primers_origin,\n",
    "                                                taxonomy_level=taxonomy_level,\n",
    "                                                selected_primer=selected_primer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 s, sys: 1.52 s, total: 6.23 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024423480083857444"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.66/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_test_results = y_pred\n",
    "chosen_order_test_results = [dict_genus_to_order[pred] for pred in y_pred]\n",
    "chosen_family_test_results = [dict_genus_to_family[pred] for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_class_test_results = np.array(y_test.genus)\n",
    "real_order_test_results = [dict_genus_to_order[c] for c in real_class_test_results]\n",
    "real_family_test_results = [dict_genus_to_family[c] for c in real_class_test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_train_results = RF.predict(X_train)\n",
    "chosen_order_train_results = [dict_genus_to_order[c] for c in chosen_class_train_results]\n",
    "chosen_family_train_results = [dict_genus_to_family[c] for c in chosen_class_train_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_class_train_results = np.array(y_train.genus)\n",
    "real_order_train_results = [dict_genus_to_order[c] for c in real_class_train_results]\n",
    "real_family_train_results = [dict_genus_to_family[c] for c in real_class_train_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic error probability: 0.31%\n",
      "Basic error probability at family level: 0.05%\n",
      "Basic error probability at order level: 0.05%\n"
     ]
    }
   ],
   "source": [
    "absolute_train_errors = [chosen_class_train_results[i] != real_class_train_results[i] for i in range(len(real_class_train_results))]\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_class_train_results))) * 100))\n",
    "absolute_train_errors = [chosen_family_train_results[i] != real_family_train_results[i] for i in range(len(real_family_train_results))]\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_family_train_results))) * 100))\n",
    "absolute_train_errors = [chosen_order_train_results[i] != real_order_train_results[i] for i in range(len(real_order_train_results))]\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(real_order_train_results))) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic error probability: 31.81%\n",
      "Basic error probability at family level: 13.94%\n",
      "Basic error probability at order level: 8.96%\n"
     ]
    }
   ],
   "source": [
    "absolute_test_errors = [chosen_class_test_results[i] != real_class_test_results[i] for i in range(len(real_class_test_results))]\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_class_test_results))) * 100))\n",
    "absolute_test_errors = [chosen_family_test_results[i] != real_family_test_results[i] for i in range(len(real_family_test_results))]\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_family_test_results))) * 100))\n",
    "absolute_test_errors = [chosen_order_test_results[i] != real_order_test_results[i] for i in range(len(real_order_test_results))]\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(real_order_test_results))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_config = {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'V4', 'taxonomy_level':5, 'dimension':2, 'k_mer':1, 'vector_max_size':300, 'out_channel_1':254, 'out_channel_2':254, 'kernel_size_1_W':5, 'kernel_size_2_W':30, 'max_pool_stride_1_W':5, 'max_pool_stride_2_W':30, 'n_epochs':50, 'learning_rate':1e-3}\n",
    "max_size = parameter_config['vector_max_size']\n",
    "k_mer = parameter_config['k_mer']\n",
    "\n",
    "analysis_path =  'model_results\\\\00018_analysis_V4_5_good\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin=parameter_config['sequence_origin'], \n",
    "                                                               primers_origin=parameter_config['primers_origin'], \n",
    "                                                               selected_primer=parameter_config['selected_primer'], \n",
    "                                                               taxonomy_level=parameter_config['taxonomy_level'])\n",
    "train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=parameter_config['sequence_origin'], \n",
    "        primers_origin=parameter_config['primers_origin'],\n",
    "        selected_primer=parameter_config['selected_primer'], \n",
    "        taxonomy_level=parameter_config['taxonomy_level'],\n",
    "        max_size=max_size,\n",
    "        k_mer=k_mer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out_features = len(dict_id_to_class)\n",
    "\n",
    "conv_class = classifier_GD_2_ACM(n_out_features=n_out_features,\n",
    "                                 parameter_config=parameter_config)\n",
    "\n",
    "model_path = analysis_path + 'model.pt'\n",
    "\n",
    "conv_class.load_state_dict(torch.load(model_path))\n",
    "conv_class.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test\n",
    "train_loader, test_loader\n",
    "dict_class_to_id, dict_id_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_col = X_test.iloc[:, 1]\n",
    "y_test_col = y_test.iloc[:, 1]\n",
    "X_train_col = X_train.iloc[:, 1] \n",
    "y_train_col = y_train.iloc[:, 1] \n",
    "new_X_test = np.array([get_homogenous_vector(X_test_col[i], max_size).transpose() for i in range(len(X_test))])\n",
    "new_X_train = np.array([get_homogenous_vector(X_train_col[i], max_size).transpose() for i in range(len(X_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_tour_proba(probs, threshold=0.2):\n",
    "    validated_classes = [prob > threshold for prob in probs] \n",
    "    new_sum = np.sum([validated_classes[i] * probs[i] for i in range(len(probs))])\n",
    "    if new_sum == 0:\n",
    "        return probs\n",
    "    adjusted_probs = [validated_classes[i] * probs[i] / new_sum for i in range(len(probs))]\n",
    "    return adjusted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_class_choice(probs):\n",
    "    idx = np.argmax(probs)\n",
    "    new_binary_probs = np.zeros(probs.shape)\n",
    "    new_binary_probs[idx] = 1\n",
    "    return new_binary_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_results = np.zeros((len(X_train), n_out_features))\n",
    "for index in range(len(X_train)):\n",
    "    seq = X_train_col[index]\n",
    "    X_sample = torch.from_numpy(new_X_train[index].astype(np.float32))\n",
    "    y_sample = y_train_col[index]\n",
    "    seq_variable = Variable(X_sample.unsqueeze(0))\n",
    "    logit = conv_class(seq_variable)\n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    train_probs_results[index] = h_x\n",
    "    #probs, idx = h_x.sort(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_train_results = np.zeros(train_probs_results.shape)\n",
    "for index in range(len(train_probs_results)):\n",
    "    chosen_class_train_results[index] = max_class_choice(train_probs_results[index])\n",
    "train_real_classes = np.zeros(train_probs_results.shape)\n",
    "for index in range(len(train_probs_results)):\n",
    "    train_real_classes[index, dict_class_to_id[y_train_col[index]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_train_errors = np.abs(chosen_class_train_results-train_real_classes)\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(train_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_train_probs_results = np.zeros(train_probs_results.shape)\n",
    "for index in range(len(train_probs_results)):\n",
    "    adjusted_train_probs_results[index] = second_tour_proba(train_probs_results[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_absolute_train_errors = np.abs(adjusted_train_probs_results-train_real_classes)\n",
    "print('Adjusted error probability: {:.2f}%'.format(((np.sum(adjusted_absolute_train_errors) / len(train_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_results = np.zeros((len(X_test), n_out_features))\n",
    "for index in range(len(X_test)):\n",
    "    seq = X_test_col[index]\n",
    "    X_sample = torch.from_numpy(new_X_test[index].astype(np.float32))\n",
    "    y_sample = y_test_col[index]\n",
    "    seq_variable = Variable(X_sample.unsqueeze(0))\n",
    "    logit = conv_class(seq_variable)\n",
    "    h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "    test_probs_results[index] = h_x\n",
    "    #probs, idx = h_x.sort(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_test_results = np.zeros(test_probs_results.shape)\n",
    "for index in range(len(test_probs_results)):\n",
    "    chosen_class_test_results[index] = max_class_choice(test_probs_results[index])\n",
    "test_real_classes = np.zeros(test_probs_results.shape)\n",
    "for index in range(len(test_probs_results)):\n",
    "    test_real_classes[index, dict_class_to_id[y_test_col[index]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_test_errors = np.abs(chosen_class_test_results-test_real_classes)\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(test_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_test_probs_results = np.zeros(test_probs_results.shape)\n",
    "for index in range(len(test_probs_results)):\n",
    "    adjusted_test_probs_results[index] = second_tour_proba(test_probs_results[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_absolute_test_errors = np.abs(adjusted_test_probs_results-test_real_classes)\n",
    "print('Adjusted error probability: {:.2f}%'.format(((np.sum(adjusted_absolute_test_errors) / len(test_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train_probs_results = np.sum(adjusted_train_probs_results, axis=0)\n",
    "global_test_probs_results = np.sum(adjusted_test_probs_results, axis=0)\n",
    "global_train_real_classes = np.sum(train_real_classes, axis=0)\n",
    "global_test_real_classes = np.sum(test_real_classes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results_df = pd.DataFrame()\n",
    "aggregated_results_df['Genus'] = dict_id_to_class.values()\n",
    "aggregated_results_df['Train Real Occurences']  = global_train_real_classes\n",
    "aggregated_results_df['Train Model Adjusted Occurences'] = global_train_probs_results\n",
    "aggregated_results_df['Test Real Occurences']  = global_test_real_classes\n",
    "aggregated_results_df['Test Model Adjusted Occurences'] = global_test_probs_results\n",
    " \n",
    "\n",
    "aggregated_results_df.to_csv('Aggregated_cnn_results.csv', index=False, sep=\";\")\n",
    "# Then Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results_df.melt(id_vars='Genus', var_name='Results from', value_name='Occurences').to_csv('Melted_cnn_results.csv',index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing one rank above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving  the new predictions / real classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results used are those from chosen_class_train_results, chosen_class_test_results, adjusted_train_probs_results, adjusted_test_probs_results, compared to the real classes in train_real_classes and test_real_classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_id_to_class permet de passer du numéro id parmi les 16XX GENUS au GENUS utilisé dans les dict_genus_to_family etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_genus_to_higher_rank(model_results, dict_genus_to, dict_xxx_to_id, dict_id_to_class):\n",
    "    higher_rank_results = np.zeros((model_results.shape[0], len(dict_xxx_to_id)))\n",
    "    for index, estim in enumerate(model_results):\n",
    "        for genus_id, genus_result in enumerate(estim):\n",
    "            higher_rank_results[index][dict_xxx_to_id[dict_genus_to[dict_id_to_class[genus_id]]]] += genus_result\n",
    "    return higher_rank_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_train_results_families = map_genus_to_higher_rank(chosen_class_train_results, dict_genus_to_family, dict_family_to_id, dict_id_to_class)\n",
    "chosen_class_test_results_families = map_genus_to_higher_rank(chosen_class_test_results, dict_genus_to_family, dict_family_to_id, dict_id_to_class)\n",
    "adjusted_train_probs_results_families = map_genus_to_higher_rank(adjusted_train_probs_results, dict_genus_to_family, dict_family_to_id, dict_id_to_class)\n",
    "adjusted_test_probs_results_families = map_genus_to_higher_rank(adjusted_test_probs_results, dict_genus_to_family, dict_family_to_id, dict_id_to_class)\n",
    "train_real_classes_families = map_genus_to_higher_rank(train_real_classes, dict_genus_to_family, dict_family_to_id, dict_id_to_class)\n",
    "test_real_classes_families = map_genus_to_higher_rank(test_real_classes, dict_genus_to_family, dict_family_to_id, dict_id_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_train_results_orders = map_genus_to_higher_rank(chosen_class_train_results, dict_genus_to_order, dict_order_to_id, dict_id_to_class)\n",
    "chosen_class_test_results_orders = map_genus_to_higher_rank(chosen_class_test_results, dict_genus_to_order, dict_order_to_id, dict_id_to_class)\n",
    "adjusted_train_probs_results_orders = map_genus_to_higher_rank(adjusted_train_probs_results, dict_genus_to_order, dict_order_to_id, dict_id_to_class)\n",
    "adjusted_test_probs_results_orders = map_genus_to_higher_rank(adjusted_test_probs_results, dict_genus_to_order, dict_order_to_id, dict_id_to_class)\n",
    "train_real_classes_orders = map_genus_to_higher_rank(train_real_classes, dict_genus_to_order, dict_order_to_id, dict_id_to_class)\n",
    "test_real_classes_orders = map_genus_to_higher_rank(test_real_classes, dict_genus_to_order, dict_order_to_id, dict_id_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_train_errors = np.abs(chosen_class_train_results-train_real_classes)\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(train_probs_results)) / 2) * 100))\n",
    "absolute_train_errors = np.abs(chosen_class_train_results_families-train_real_classes_families)\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(train_probs_results)) / 2) * 100))\n",
    "absolute_train_errors = np.abs(chosen_class_train_results_orders-train_real_classes_orders)\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_train_errors) / len(train_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_test_errors = np.abs(chosen_class_test_results-test_real_classes)\n",
    "print('Basic error probability: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(test_probs_results)) / 2) * 100))\n",
    "absolute_test_errors = np.abs(chosen_class_test_results_families-test_real_classes_families)\n",
    "print('Basic error probability at family level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(test_probs_results)) / 2) * 100))\n",
    "absolute_test_errors = np.abs(chosen_class_test_results_orders-test_real_classes_orders)\n",
    "print('Basic error probability at order level: {:.2f}%'.format(((np.sum(absolute_test_errors) / len(test_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_absolute_train_errors = np.abs(adjusted_train_probs_results-train_real_classes)\n",
    "print('Adjusted error probability: {:.2f}%'.format(((np.sum(adjusted_absolute_train_errors) / len(train_probs_results)) / 2) * 100))\n",
    "adjusted_absolute_train_errors = np.abs(adjusted_train_probs_results_families-train_real_classes_families)\n",
    "print('Adjusted error probability at family level: {:.2f}%'.format(((np.sum(adjusted_absolute_train_errors) / len(train_probs_results)) / 2) * 100))\n",
    "adjusted_absolute_train_errors = np.abs(adjusted_train_probs_results_orders-train_real_classes_orders)\n",
    "print('Adjusted error probability at order level: {:.2f}%'.format(((np.sum(adjusted_absolute_train_errors) / len(train_probs_results)) / 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_absolute_test_errors = np.abs(adjusted_test_probs_results-test_real_classes)\n",
    "print('Adjusted error probability: {:.2f}%'.format(((np.sum(adjusted_absolute_test_errors) / len(test_probs_results)) / 2) * 100))\n",
    "adjusted_absolute_test_errors = np.abs(adjusted_test_probs_results_families-test_real_classes_families)\n",
    "print('Adjusted error probability at family level: {:.2f}%'.format(((np.sum(adjusted_absolute_test_errors) / len(test_probs_results)) / 2) * 100))\n",
    "adjusted_absolute_test_errors = np.abs(adjusted_test_probs_results_orders-test_real_classes_orders)\n",
    "print('Adjusted error probability at order level: {:.2f}%'.format(((np.sum(adjusted_absolute_test_errors) / len(test_probs_results)) / 2) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
