{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-functions\" data-toc-modified-id=\"Load-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load functions</a></span></li><li><span><a href=\"#Training-a-first-simple-NN\" data-toc-modified-id=\"Training-a-first-simple-NN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training a first simple NN</a></span></li><li><span><a href=\"#Looping-over-different-configuration-for-1D\" data-toc-modified-id=\"Looping-over-different-configuration-for-1D-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Looping over different configuration for 1D</a></span></li><li><span><a href=\"#Looping-over-different-configuration-for-2D\" data-toc-modified-id=\"Looping-over-different-configuration-for-2D-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Looping over different configuration for 2D</a></span></li><li><span><a href=\"#Looping-over-different-configurations-for-2D---ACM\" data-toc-modified-id=\"Looping-over-different-configurations-for-2D---ACM-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Looping over different configurations for 2D - ACM</a></span></li><li><span><a href=\"#ACTIVATION-MAP-Manually\" data-toc-modified-id=\"ACTIVATION-MAP-Manually-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>ACTIVATION MAP Manually</a></span></li><li><span><a href=\"#Get-model-structure-image\" data-toc-modified-id=\"Get-model-structure-image-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Get model structure image</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from models.cnn_model import classifier_GD_1, classifier_GD_2\n",
    "from models.cnn_preprocessing import main_preprocessing_cnn\n",
    "from models.cnn_train_test import train, test\n",
    "from models.cnn_model_statistics import main_cnn_stats_model\n",
    "from models.loading_model_data import main_loading_model_data\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a first simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(selected_primer='V4', taxonomy_level=1)\n",
    "X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin='DairyDB', primers_origin='DairyDB', selected_primer='V4', taxonomy_level=1)\n",
    "n_out_features = len(dict_class_to_id)\n",
    "\n",
    "out_channel_1 = 30  # 10\n",
    "out_channel_2 = 30  # 20\n",
    "kernel_size_1_W = 7  # 7\n",
    "kernel_size_2_W = 7  # 7\n",
    "ratio_fc_1 = 1 / 2  # 1 / 2\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "conv_class = classifier_GD_2(n_out_features)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_train, acc_train, loss_test, acc_test = train(conv_class, train_loader, test_loader, loss_fn, optimizer_cl, n_epochs=n_epochs)\n",
    "_, _, y_test_torch, y_pred_torch = test(conv_class, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main_cnn_stats_model(y_train, y_test_torch, y_pred_torch, dict_id_to_class, loss_train, loss_test, acc_train, acc_test,\n",
    "                     make_plot=True,\n",
    "                     model_name='CNN - Aoki - 2D',\n",
    "                     model_class=conv_class,\n",
    "                     model_preprocessing='OHE of letters in 4 dimensions (k=1)',\n",
    "                     sequence_origin='DairyDB',\n",
    "                     primers_origin='DairyDB',\n",
    "                     taxonomy_level=1,\n",
    "                     selected_primer='V4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over different configuration for 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from models.cnn_preprocessing import main_preprocessing_cnn\n",
    "from models.cnn_train_test import train, test\n",
    "from models.cnn_model_statistics import main_cnn_stats_model\n",
    "from models.loading_model_data import main_loading_model_data\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import save_update_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class classifier_GD_1(nn.Module):\n",
    "\n",
    "    def __init__(self, n_out_features: int, k_mer: int = 1, max_size: int = 300):\n",
    "        self.k_mer = k_mer\n",
    "        self.max_size = max_size\n",
    "        super(classifier_GD_1, self).__init__()\n",
    "        # PARAMETERS\n",
    "        self.out_channel_1 = out_channel_1\n",
    "        self.out_channel_2 = out_channel_2\n",
    "        self.kernel_size_1 = kernel_size_1\n",
    "        self.max_pool_stride_1 = max_pool_stride_1\n",
    "        self.max_pool_stride_2 = max_pool_stride_2\n",
    "        self.ratio_fc_1 = ratio_fc_1\n",
    "        # COPIED PARAMETERS\n",
    "        self.kernel_size_max_pool_1 = self.kernel_size_1\n",
    "        self.kernel_size_2 = self.kernel_size_1\n",
    "        # SIZE COMPUTATION\n",
    "        self.L_out_conv_1 = max_size - self.kernel_size_1 + 1\n",
    "        self.L_out_max_pool_1 = int((self.L_out_conv_1 - self.kernel_size_1) // self.max_pool_stride_1) + 1\n",
    "        self.L_out_conv_2 = self.L_out_max_pool_1 - self.kernel_size_2 + 1\n",
    "        self.L_out_max_pool_2 = int((self.L_out_conv_2 - self.kernel_size_2) // self.max_pool_stride_2) + 1\n",
    "        self.L_out_fc_1 = int(self.out_channel_2 * self.L_out_max_pool_2 * self.ratio_fc_1)\n",
    "\n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=4 ** k_mer, out_channels=self.out_channel_1,\n",
    "                               kernel_size=self.kernel_size_1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(self.out_channel_1)\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        # Layers\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.out_channel_1, out_channels=self.out_channel_2,\n",
    "                               kernel_size=self.kernel_size_2, padding=0)\n",
    "        self.bn2 = nn.BatchNorm1d(self.out_channel_2)\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        # Hidden part\n",
    "        self.fc1 = nn.Linear(in_features=self.out_channel_2 * self.L_out_max_pool_2,\n",
    "                             out_features=self.L_out_fc_1)\n",
    "        self.ReLU3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=self.L_out_fc_1,\n",
    "                             out_features=n_out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = F.max_pool1d(x, kernel_size=self.kernel_size_1, stride=self.max_pool_stride_1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = F.max_pool1d(x, kernel_size=self.kernel_size_2, stride=self.max_pool_stride_2)\n",
    "        x = x.view(-1, self.out_channel_2 * self.L_out_max_pool_2)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU3(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc2(x)\n",
    "        return x  # With CrossEntropyLoss directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colnames = ['sequence_origin','primers_origin','selected_primer','taxonomy_level','dimension','k_mer','vector_max_size','out_channel_1','out_channel_2','kernel_size_1','max_pool_stride_1', 'max_pool_stride_2','ratio_fc_1','n_epochs','learning_rate','accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_config_list = [\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':50,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':100,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':150,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':200,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':250,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB','primers_origin':'DairyDB','selected_primer':'V4','taxonomy_level':1,'dimension':1,'k_mer':1,'vector_max_size':300,'out_channel_1':32,'out_channel_2':64,'kernel_size_1':6,'max_pool_stride_1':2,'max_pool_stride_2':2,'ratio_fc_1':2/3,'n_epochs':50,'learning_rate':1e-3}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for parameter_config in parameter_config_list:\n",
    "    dim = parameter_config['dimension']\n",
    "    k_mer = parameter_config['k_mer']\n",
    "    max_size = parameter_config['vector_max_size']\n",
    "    file_path = 'results/models/CNN {}D - CNN({}) - accuracies.csv'.format(\n",
    "        dim, k_mer\n",
    "    )\n",
    "    print('Working with the following parameter configuration: \\n {}'.format(parameter_config))\n",
    "    train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=parameter_config['sequence_origin'], \n",
    "        primers_origin=parameter_config['primers_origin'],\n",
    "        selected_primer=parameter_config['selected_primer'], \n",
    "        taxonomy_level=parameter_config['taxonomy_level'],\n",
    "        max_size=max_size,\n",
    "        k_mer=k_mer\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin=parameter_config['sequence_origin'], \n",
    "                                                               primers_origin=parameter_config['primers_origin'], \n",
    "                                                               selected_primer=parameter_config['selected_primer'], \n",
    "                                                               taxonomy_level=parameter_config['taxonomy_level'])\n",
    "    n_out_features = len(dict_class_to_id)\n",
    "\n",
    "    out_channel_1 = parameter_config['out_channel_1']\n",
    "    out_channel_2 = parameter_config['out_channel_2']\n",
    "    kernel_size_1 = parameter_config['kernel_size_1']\n",
    "    max_pool_stride_1 = parameter_config['max_pool_stride_1']\n",
    "    max_pool_stride_2 = parameter_config['max_pool_stride_2']\n",
    "    ratio_fc_1 = parameter_config['ratio_fc_1']\n",
    "\n",
    "    n_epochs = parameter_config['n_epochs']\n",
    "    \n",
    "    \n",
    "\n",
    "    conv_class = classifier_GD_1(n_out_features, k_mer, max_size)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate = parameter_config['learning_rate']\n",
    "    optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
    "\n",
    "    _, _, _, _ = test(conv_class, test_loader, loss_fn)\n",
    "    loss_train, acc_train, loss_test, acc_test = train(conv_class, train_loader, test_loader, loss_fn, optimizer_cl, n_epochs=n_epochs)\n",
    "    final_test_loss, accuracy, y_test_torch, y_pred_torch = test(conv_class, test_loader, loss_fn)\n",
    "    \n",
    "    parameter_config['accuracy'] = accuracy\n",
    "    \n",
    "    main_cnn_stats_model(y_train, y_test_torch, y_pred_torch, dict_id_to_class, loss_train, loss_test, acc_train, acc_test,\n",
    "                     make_plot=True,\n",
    "                     model_name='CNN - Aoki - {}D'.format(dim),\n",
    "                     model_class=conv_class,\n",
    "                     model_preprocessing='OHE of letters in {} dimensions (k={}) - max size = {}'.format(4**k_mer, k_mer, max_size),\n",
    "                     sequence_origin=parameter_config['sequence_origin'],\n",
    "                     primers_origin=parameter_config['primers_origin'],\n",
    "                     taxonomy_level=parameter_config['taxonomy_level'],\n",
    "                     selected_primer=parameter_config['selected_primer'])\n",
    "    \n",
    "    save_update_cnn(file_path, parameter_config.keys(), parameter_config.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over different configuration for 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from models.cnn_preprocessing import main_preprocessing_cnn\n",
    "from models.cnn_train_test import train, test\n",
    "from models.cnn_model_statistics import main_cnn_stats_model\n",
    "from models.loading_model_data import main_loading_model_data\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import save_update_cnn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class classifier_GD_2(nn.Module):\n",
    "\n",
    "    def __init__(self, n_out_features: int, k_mer: int = 1, max_size: int = 300):\n",
    "        super(classifier_GD_2, self).__init__()\n",
    "        self.k_mer = k_mer\n",
    "        self.max_size = max_size\n",
    "        # PARAMETERS\n",
    "        self.out_channel_1 = out_channel_1\n",
    "        self.out_channel_2 = out_channel_2\n",
    "        self.kernel_size_1_W = kernel_size_1_W\n",
    "        self.kernel_size_2_W = kernel_size_2_W\n",
    "        self.ratio_fc_1 = ratio_fc_1\n",
    "        # FIXED PARAMETERS\n",
    "        self.kernel_size_1_H = 4 ** k_mer\n",
    "        self.padding_conv_1_H = 0\n",
    "        self.padding_conv_1_W = 0\n",
    "        self.kernel_size_max_pool_1_H = 1\n",
    "        self.max_pool_stride_1_H = 1\n",
    "        self.max_pool_stride_1_W = 8\n",
    "        self.kernel_size_2_H = 1\n",
    "        self.padding_conv_2_H = 0\n",
    "        self.padding_conv_2_W = 0\n",
    "        self.kernel_size_max_pool_2_H = 1\n",
    "        self.max_pool_stride_2_H = 1\n",
    "        self.max_pool_stride_2_W = 8\n",
    "        # COPIED PARAMETERS\n",
    "        self.kernel_size_max_pool_1_W = self.kernel_size_1_W  # 7\n",
    "        self.kernel_size_max_pool_2_W = self.kernel_size_2_W  # 7\n",
    "        # SIZE COMPUTATION\n",
    "        self.L_out_conv_1_H = 4 ** k_mer - self.kernel_size_1_H + 2 * self.padding_conv_1_H + 1  # 1\n",
    "        self.L_out_conv_1_W = max_size - self.kernel_size_1_W + 2 * self.padding_conv_1_W + 1  # 294\n",
    "        self.L_out_max_pool_1_H = int((self.L_out_conv_1_H - self.kernel_size_max_pool_1_H) // self.max_pool_stride_1_H) + 1  # 1\n",
    "        self.L_out_max_pool_1_W = int((self.L_out_conv_1_W - self.kernel_size_max_pool_1_W) // self.max_pool_stride_1_W) + 1  # 36\n",
    "        self.L_out_conv_2_H = self.L_out_max_pool_1_H - self.kernel_size_2_H + 2 * self.padding_conv_2_H + 1  # 1\n",
    "        self.L_out_conv_2_W = self.L_out_max_pool_1_W - self.kernel_size_2_W + 2 * self.padding_conv_2_W + 1  # 30\n",
    "        self.L_out_max_pool_2_H = int((self.L_out_conv_2_H - self.kernel_size_max_pool_2_H) // self.max_pool_stride_2_H) + 1  # 1\n",
    "        self.L_out_max_pool_2_W = int((self.L_out_conv_2_W - self.kernel_size_max_pool_2_W) // self.max_pool_stride_2_W) + 1  # 4\n",
    "        self.L_in_fc_1 = int(self.out_channel_2 * self.L_out_max_pool_2_H * self.L_out_max_pool_2_W)  # 80\n",
    "        self.L_out_fc_1 = int(self.out_channel_2 * self.L_out_max_pool_2_H * self.L_out_max_pool_2_W * self.ratio_fc_1)  # 40\n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.out_channel_1,\n",
    "                               kernel_size=(self.kernel_size_1_H, self.kernel_size_1_W),\n",
    "                               padding=(self.padding_conv_1_H, self.padding_conv_1_W))\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channel_1)\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        # Layers\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.out_channel_1, out_channels=self.out_channel_2,\n",
    "                               kernel_size=(self.kernel_size_2_H, self.kernel_size_2_W),\n",
    "                               padding=(self.padding_conv_2_H, self.padding_conv_2_W))\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channel_2)\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        # Hidden part\n",
    "        self.fc1 = nn.Linear(in_features=self.L_in_fc_1,\n",
    "                             out_features=self.L_out_fc_1)\n",
    "        self.ReLU3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=self.L_out_fc_1,\n",
    "                             out_features=n_out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 4 ** self.k_mer, self.max_size)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = F.max_pool2d(x,\n",
    "                         kernel_size=(self.kernel_size_max_pool_1_H, self.kernel_size_max_pool_1_W),\n",
    "                         stride=(self.max_pool_stride_1_H, self.max_pool_stride_1_W))\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = F.max_pool2d(x,\n",
    "                         kernel_size=(self.kernel_size_max_pool_2_H, self.kernel_size_max_pool_2_W),\n",
    "                         stride=(self.max_pool_stride_2_H, self.max_pool_stride_2_W))\n",
    "        x = x.view(-1, self.L_in_fc_1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU3(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc2(x)\n",
    "        return x  # With CrossEntropyLoss directly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colnames = ['sequence_origin','primers_origin','selected_primer','taxonomy_level','dimension','k_mer','vector_max_size','out_channel_1','out_channel_2','kernel_size_1_W','kernel_size_2_W','max_pool_stride_1_W','max_pool_stride_2_W','ratio_fc_1','n_epochs','learning_rate','accuracy', 'training_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_config_list = [\n",
    "    {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'V4', 'taxonomy_level':1, 'dimension':2, 'k_mer':1, 'vector_max_size':300, 'out_channel_1':32, 'out_channel_2':64, 'kernel_size_1_W':8, 'kernel_size_2_W':8, 'max_pool_stride_1_W':8, 'max_pool_stride_2_W':8, 'ratio_fc_1':1/2, 'n_epochs':50, 'learning_rate':1e-3}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for parameter_config in parameter_config_list:\n",
    "    dim = parameter_config['dimension']\n",
    "    k_mer = parameter_config['k_mer']\n",
    "    max_size = parameter_config['vector_max_size']\n",
    "    file_path = 'results/models/CNN {}D - CNN({}) - accuracies.csv'.format(\n",
    "        dim, k_mer\n",
    "    )\n",
    "    print('Working with the following parameter configuration: \\n {}'.format(parameter_config))\n",
    "    train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=parameter_config['sequence_origin'], \n",
    "        primers_origin=parameter_config['primers_origin'],\n",
    "        selected_primer=parameter_config['selected_primer'], \n",
    "        taxonomy_level=parameter_config['taxonomy_level'],\n",
    "        max_size=max_size,\n",
    "        k_mer=k_mer\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin=parameter_config['sequence_origin'], \n",
    "                                                               primers_origin=parameter_config['primers_origin'], \n",
    "                                                               selected_primer=parameter_config['selected_primer'], \n",
    "                                                               taxonomy_level=parameter_config['taxonomy_level'])\n",
    "    n_out_features = len(dict_class_to_id)\n",
    "\n",
    "    out_channel_1 = parameter_config['out_channel_1']\n",
    "    out_channel_2 = parameter_config['out_channel_2']\n",
    "    kernel_size_1_W = parameter_config['kernel_size_1_W']\n",
    "    kernel_size_2_W = parameter_config['kernel_size_2_W']\n",
    "    ratio_fc_1 = parameter_config['ratio_fc_1']\n",
    "\n",
    "    n_epochs = parameter_config['n_epochs']\n",
    "    \n",
    "    \n",
    "\n",
    "    conv_class = classifier_GD_2(n_out_features, k_mer, max_size)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate = parameter_config['learning_rate']\n",
    "    optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
    "\n",
    "    _, _, _, _ = test(conv_class, test_loader, loss_fn)\n",
    "    begin_time = time.time()\n",
    "    loss_train, acc_train, loss_test, acc_test = train(conv_class, train_loader, test_loader, loss_fn, optimizer_cl, n_epochs=n_epochs)\n",
    "    end_time = time.time()\n",
    "    final_test_loss, accuracy, y_test_torch, y_pred_torch = test(conv_class, test_loader, loss_fn)\n",
    "    \n",
    "    parameter_config['accuracy'] = accuracy\n",
    "    parameter_config['training_time'] = end_time - begin_time\n",
    "    \n",
    "    main_cnn_stats_model(y_train, y_test_torch, y_pred_torch, dict_id_to_class, loss_train, loss_test, acc_train, acc_test,\n",
    "                     make_plot=True,\n",
    "                     model_name='CNN - Aoki - {}D'.format(dim),\n",
    "                     model_class=conv_class,\n",
    "                     model_preprocessing='OHE of letters in {} dimensions (k={}) - max size = {}'.format(4**k_mer, k_mer, max_size),\n",
    "                     sequence_origin=parameter_config['sequence_origin'],\n",
    "                     primers_origin=parameter_config['primers_origin'],\n",
    "                     taxonomy_level=parameter_config['taxonomy_level'],\n",
    "                     selected_primer=parameter_config['selected_primer'])\n",
    "    \n",
    "    save_update_cnn(file_path, parameter_config.keys(), parameter_config.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over different configurations for 2D - ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn_model import classifier_GD_2_ACM\n",
    "from models.cnn_preprocessing import main_preprocessing_cnn\n",
    "from models.cnn_train_test import train, test\n",
    "from models.cnn_model_statistics import main_cnn_stats_model\n",
    "from models.loading_model_data import main_loading_model_data\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import save_update_cnn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['sequence_origin','primers_origin','selected_primer','taxonomy_level','dimension','k_mer','vector_max_size','out_channel_1','out_channel_2','kernel_size_1_W','kernel_size_2_W','max_pool_stride_1_W','max_pool_stride_2_W','n_epochs','learning_rate','accuracy','training_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_config_list = [\n",
    "    {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'V4', 'taxonomy_level':5, 'dimension':2, 'k_mer':1, 'vector_max_size':300, 'out_channel_1':254, 'out_channel_2':254, 'kernel_size_1_W':5, 'kernel_size_2_W':30, 'max_pool_stride_1_W':5, 'max_pool_stride_2_W':15, 'n_epochs':50, 'learning_rate':1e-3},\n",
    "    {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'V4', 'taxonomy_level':5, 'dimension':2, 'k_mer':1, 'vector_max_size':300, 'out_channel_1':254, 'out_channel_2':254, 'kernel_size_1_W':5, 'kernel_size_2_W':30, 'max_pool_stride_1_W':5, 'max_pool_stride_2_W':30, 'n_epochs':50, 'learning_rate':1e-3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with the following parameter configuration: \n",
      " {'sequence_origin': 'DairyDB', 'primers_origin': 'DairyDB', 'selected_primer': 'V4', 'taxonomy_level': 5, 'dimension': 2, 'k_mer': 1, 'vector_max_size': 300, 'out_channel_1': 254, 'out_channel_2': 254, 'kernel_size_1_W': 5, 'kernel_size_2_W': 30, 'max_pool_stride_1_W': 5, 'max_pool_stride_2_W': 15, 'n_epochs': 50, 'learning_rate': 0.001}\n",
      "Test - Loss: 0.1171 Acc: 0.0010\n",
      "Epoch 1 over 50\n",
      "Train - Loss: 0.1067 Acc: 0.1085\n",
      "Test - Loss: 0.0971 Acc: 0.1678\n",
      "Epoch 2 over 50\n",
      "Train - Loss: 0.0890 Acc: 0.1690\n",
      "Test - Loss: 0.0872 Acc: 0.2018\n",
      "Epoch 3 over 50\n",
      "Train - Loss: 0.0766 Acc: 0.2488\n",
      "Test - Loss: 0.0790 Acc: 0.2578\n",
      "Epoch 4 over 50\n",
      "Train - Loss: 0.0665 Acc: 0.3153\n",
      "Test - Loss: 0.0727 Acc: 0.3360\n",
      "Epoch 5 over 50\n",
      "Train - Loss: 0.0570 Acc: 0.3953\n",
      "Test - Loss: 0.0672 Acc: 0.3742\n",
      "Epoch 6 over 50\n",
      "Train - Loss: 0.0492 Acc: 0.4456\n",
      "Test - Loss: 0.0611 Acc: 0.4189\n",
      "Epoch 7 over 50\n",
      "Train - Loss: 0.0424 Acc: 0.4985\n",
      "Test - Loss: 0.0577 Acc: 0.4530\n",
      "Epoch 8 over 50\n",
      "Train - Loss: 0.0370 Acc: 0.5402\n",
      "Test - Loss: 0.0549 Acc: 0.4799\n",
      "Epoch 9 over 50\n",
      "Train - Loss: 0.0325 Acc: 0.5791\n",
      "Test - Loss: 0.0539 Acc: 0.4891\n",
      "Epoch 10 over 50\n",
      "Train - Loss: 0.0284 Acc: 0.6065\n",
      "Test - Loss: 0.0546 Acc: 0.5028\n",
      "Epoch 11 over 50\n",
      "Train - Loss: 0.0246 Acc: 0.6434\n",
      "Test - Loss: 0.0532 Acc: 0.5211\n",
      "Epoch 12 over 50\n",
      "Train - Loss: 0.0221 Acc: 0.6685\n",
      "Test - Loss: 0.0516 Acc: 0.5384\n",
      "Epoch 13 over 50\n",
      "Train - Loss: 0.0197 Acc: 0.6931\n",
      "Test - Loss: 0.0522 Acc: 0.5470\n",
      "Epoch 14 over 50\n",
      "Train - Loss: 0.0175 Acc: 0.7187\n",
      "Test - Loss: 0.0528 Acc: 0.5557\n",
      "Epoch 15 over 50\n",
      "Train - Loss: 0.0163 Acc: 0.7289\n",
      "Test - Loss: 0.0535 Acc: 0.5602\n",
      "Epoch 16 over 50\n",
      "Train - Loss: 0.0142 Acc: 0.7560\n",
      "Test - Loss: 0.0536 Acc: 0.5572\n",
      "Epoch 17 over 50\n",
      "Train - Loss: 0.0132 Acc: 0.7699\n",
      "Test - Loss: 0.0544 Acc: 0.5755\n",
      "Epoch 18 over 50\n",
      "Train - Loss: 0.0123 Acc: 0.7779\n",
      "Test - Loss: 0.0543 Acc: 0.5633\n",
      "Epoch 19 over 50\n",
      "Train - Loss: 0.0113 Acc: 0.7892\n",
      "Test - Loss: 0.0530 Acc: 0.5801\n",
      "Epoch 20 over 50\n",
      "Train - Loss: 0.0103 Acc: 0.8130\n",
      "Test - Loss: 0.0547 Acc: 0.5953\n",
      "Epoch 21 over 50\n",
      "Train - Loss: 0.0099 Acc: 0.8149\n",
      "Test - Loss: 0.0567 Acc: 0.5913\n",
      "Epoch 22 over 50\n",
      "Train - Loss: 0.0092 Acc: 0.8268\n",
      "Test - Loss: 0.0565 Acc: 0.5867\n",
      "Epoch 23 over 50\n",
      "Train - Loss: 0.0088 Acc: 0.8306\n",
      "Test - Loss: 0.0557 Acc: 0.5913\n",
      "Epoch 24 over 50\n",
      "Train - Loss: 0.0079 Acc: 0.8529\n",
      "Test - Loss: 0.0565 Acc: 0.5918\n",
      "Epoch 25 over 50\n",
      "Train - Loss: 0.0074 Acc: 0.8520\n",
      "Test - Loss: 0.0597 Acc: 0.5907\n",
      "Epoch 26 over 50\n",
      "Train - Loss: 0.0071 Acc: 0.8581\n",
      "Test - Loss: 0.0613 Acc: 0.5943\n",
      "Epoch 27 over 50\n",
      "Train - Loss: 0.0070 Acc: 0.8582\n",
      "Test - Loss: 0.0578 Acc: 0.6065\n",
      "Epoch 28 over 50\n",
      "Train - Loss: 0.0066 Acc: 0.8678\n",
      "Test - Loss: 0.0613 Acc: 0.6004\n",
      "Epoch 29 over 50\n",
      "Train - Loss: 0.0059 Acc: 0.8821\n",
      "Test - Loss: 0.0610 Acc: 0.5989\n",
      "Epoch 30 over 50\n",
      "Train - Loss: 0.0061 Acc: 0.8777\n",
      "Test - Loss: 0.0621 Acc: 0.6162\n",
      "Epoch 31 over 50\n",
      "Train - Loss: 0.0055 Acc: 0.8872\n",
      "Test - Loss: 0.0618 Acc: 0.6085\n",
      "Epoch 32 over 50\n",
      "Train - Loss: 0.0056 Acc: 0.8857\n",
      "Test - Loss: 0.0645 Acc: 0.5984\n",
      "Epoch 33 over 50\n",
      "Train - Loss: 0.0057 Acc: 0.8870\n",
      "Test - Loss: 0.0663 Acc: 0.6116\n",
      "Epoch 34 over 50\n",
      "Train - Loss: 0.0049 Acc: 0.9004\n",
      "Test - Loss: 0.0636 Acc: 0.6207\n",
      "Epoch 35 over 50\n",
      "Train - Loss: 0.0051 Acc: 0.8942\n",
      "Test - Loss: 0.0630 Acc: 0.6080\n",
      "Epoch 36 over 50\n",
      "Train - Loss: 0.0048 Acc: 0.9014\n",
      "Test - Loss: 0.0642 Acc: 0.6162\n",
      "Epoch 37 over 50\n",
      "Train - Loss: 0.0051 Acc: 0.8966\n",
      "Test - Loss: 0.0655 Acc: 0.6131\n",
      "Epoch 38 over 50\n",
      "Train - Loss: 0.0049 Acc: 0.8988\n",
      "Test - Loss: 0.0653 Acc: 0.6126\n",
      "Epoch 39 over 50\n",
      "Train - Loss: 0.0045 Acc: 0.9072\n",
      "Test - Loss: 0.0622 Acc: 0.6243\n",
      "Epoch 40 over 50\n",
      "Train - Loss: 0.0042 Acc: 0.9127\n",
      "Test - Loss: 0.0653 Acc: 0.6151\n",
      "Epoch 41 over 50\n",
      "Train - Loss: 0.0043 Acc: 0.9092\n",
      "Test - Loss: 0.0632 Acc: 0.6157\n",
      "Epoch 42 over 50\n",
      "Train - Loss: 0.0040 Acc: 0.9166\n",
      "Test - Loss: 0.0665 Acc: 0.6233\n",
      "Epoch 43 over 50\n",
      "Train - Loss: 0.0041 Acc: 0.9145\n",
      "Test - Loss: 0.0678 Acc: 0.6075\n",
      "Epoch 44 over 50\n",
      "Train - Loss: 0.0040 Acc: 0.9193\n",
      "Test - Loss: 0.0676 Acc: 0.6157\n",
      "Epoch 45 over 50\n",
      "Train - Loss: 0.0040 Acc: 0.9181\n",
      "Test - Loss: 0.0691 Acc: 0.6207\n",
      "Epoch 46 over 50\n",
      "Train - Loss: 0.0038 Acc: 0.9209\n",
      "Test - Loss: 0.0658 Acc: 0.6324\n",
      "Epoch 47 over 50\n",
      "Train - Loss: 0.0035 Acc: 0.9319\n",
      "Test - Loss: 0.0673 Acc: 0.6197\n",
      "Epoch 48 over 50\n",
      "Train - Loss: 0.0033 Acc: 0.9300\n",
      "Test - Loss: 0.0713 Acc: 0.6126\n",
      "Epoch 49 over 50\n",
      "Train - Loss: 0.0032 Acc: 0.9324\n",
      "Test - Loss: 0.0684 Acc: 0.6258\n",
      "Epoch 50 over 50\n",
      "Train - Loss: 0.0035 Acc: 0.9284\n",
      "Test - Loss: 0.0654 Acc: 0.6375\n",
      "Test - Loss: 0.0664 Acc: 0.6202\n",
      "Real class: ALISTIPES\n",
      "1.000 -> ALISTIPES\n",
      "0.000 -> CLOSTRIDIUM\n",
      "Real class: WEISSELLA\n",
      "0.753 -> TSUKAMURELLA\n",
      "0.210 -> WEISSELLA\n",
      "Real class: AZOSPIRILLUM\n",
      "0.999 -> AZOSPIRILLUM\n",
      "0.001 -> RHODOSPIRILLACEAE_GENUS\n",
      "Real class: SYNECHOCOCCUS\n",
      "0.534 -> CHRYSEOBACTERIUM\n",
      "0.182 -> PSEUDANABAENA\n",
      "Real class: [EUBACTERIUM]_NODATUM_GROUP\n",
      "0.958 -> ANAEROVORAX\n",
      "0.034 -> [EUBACTERIUM]_NODATUM_GROUP\n",
      "Real class: ANAEROBACTERIUM\n",
      "1.000 -> ANAEROBACTERIUM\n",
      "0.000 -> RHODOSPIRILLACEAE_GENUS\n",
      "Real class: CHELATOCOCCUS\n",
      "0.775 -> GRACILIBACTER\n",
      "0.099 -> PYRINOMONAS\n",
      "Real class: GRACILIMONAS\n",
      "1.000 -> GRACILIMONAS\n",
      "0.000 -> ALIIFODINIBIUS\n",
      "Real class: RHODOSPIRILLACEAE_GENUS\n",
      "0.992 -> RHODOSPIRILLACEAE_GENUS\n",
      "0.007 -> REYRANELLA\n",
      "Real class: CLOSTRIDIALES_VADINBB60_GROUP_GENUS\n",
      "0.995 -> CLOSTRIDIALES_VADINBB60_GROUP_GENUS\n",
      "0.005 -> CHRISTENSENELLACEAE_R-7_GROUP\n",
      "Real class: BUTYRIVIBRIO\n",
      "0.987 -> BUTYRIVIBRIO\n",
      "0.012 -> FRUCTOBACILLUS\n",
      "Real class: NAKAMURELLA\n",
      "0.676 -> SPORICHTHYA\n",
      "0.074 -> SACCHAROPOLYSPORA\n",
      "Real class: ACINETOBACTER\n",
      "0.999 -> ACINETOBACTER\n",
      "0.001 -> ALKANINDIGES\n",
      "Real class: RIKENELLACEAE_RC9_GUT_GROUP\n",
      "0.997 -> RIKENELLACEAE_RC9_GUT_GROUP\n",
      "0.002 -> RIKENELLACEAE_U29-B03\n",
      "Real class: PHOTORHABDUS\n",
      "0.971 -> XENORHABDUS\n",
      "0.015 -> ARSENOPHONUS\n",
      "Real class: ACHOLEPLASMA\n",
      "0.996 -> ACHOLEPLASMA\n",
      "0.004 -> MOLLICUTES_NB1-N_GENUS\n",
      "Real class: BIFIDOBACTERIUM\n",
      "1.000 -> BIFIDOBACTERIUM\n",
      "0.000 -> PLASTICICUMULANS\n",
      "Real class: ALGORIPHAGUS\n",
      "1.000 -> ALGORIPHAGUS\n",
      "0.000 -> SPHINGOBACTERIUM\n",
      "Real class: RUBRITALEA\n",
      "0.981 -> LUTEOLIBACTER\n",
      "0.008 -> ROSEIMICROBIUM\n",
      "Real class: RUMINOCOCCACEAE_GENUS\n",
      "0.737 -> RUMINOCOCCACEAE_GENUS\n",
      "0.095 -> FLAVONIFRACTOR\n",
      "Working with the following parameter configuration: \n",
      " {'sequence_origin': 'DairyDB', 'primers_origin': 'DairyDB', 'selected_primer': 'V4', 'taxonomy_level': 5, 'dimension': 2, 'k_mer': 1, 'vector_max_size': 300, 'out_channel_1': 254, 'out_channel_2': 254, 'kernel_size_1_W': 5, 'kernel_size_2_W': 30, 'max_pool_stride_1_W': 5, 'max_pool_stride_2_W': 30, 'n_epochs': 50, 'learning_rate': 0.001}\n",
      "Test - Loss: 0.1176 Acc: 0.0005\n",
      "Epoch 1 over 50\n",
      "Train - Loss: 0.1077 Acc: 0.0923\n",
      "Test - Loss: 0.0981 Acc: 0.1434\n",
      "Epoch 2 over 50\n",
      "Train - Loss: 0.0890 Acc: 0.1703\n",
      "Test - Loss: 0.0880 Acc: 0.1962\n",
      "Epoch 3 over 50\n",
      "Train - Loss: 0.0765 Acc: 0.2497\n",
      "Test - Loss: 0.0774 Acc: 0.2766\n",
      "Epoch 4 over 50\n",
      "Train - Loss: 0.0656 Acc: 0.3275\n",
      "Test - Loss: 0.0717 Acc: 0.3340\n",
      "Epoch 5 over 50\n",
      "Train - Loss: 0.0564 Acc: 0.3992\n",
      "Test - Loss: 0.0640 Acc: 0.3849\n",
      "Epoch 6 over 50\n",
      "Train - Loss: 0.0486 Acc: 0.4561\n",
      "Test - Loss: 0.0606 Acc: 0.4265\n",
      "Epoch 7 over 50\n",
      "Train - Loss: 0.0420 Acc: 0.4994\n",
      "Test - Loss: 0.0570 Acc: 0.4565\n",
      "Epoch 8 over 50\n",
      "Train - Loss: 0.0367 Acc: 0.5477\n",
      "Test - Loss: 0.0553 Acc: 0.4891\n",
      "Epoch 9 over 50\n",
      "Train - Loss: 0.0315 Acc: 0.5882\n",
      "Test - Loss: 0.0547 Acc: 0.5023\n",
      "Epoch 10 over 50\n",
      "Train - Loss: 0.0274 Acc: 0.6227\n",
      "Test - Loss: 0.0516 Acc: 0.5369\n",
      "Epoch 11 over 50\n",
      "Train - Loss: 0.0246 Acc: 0.6464\n",
      "Test - Loss: 0.0511 Acc: 0.5262\n",
      "Epoch 12 over 50\n",
      "Train - Loss: 0.0209 Acc: 0.6809\n",
      "Test - Loss: 0.0518 Acc: 0.5440\n",
      "Epoch 13 over 50\n",
      "Train - Loss: 0.0191 Acc: 0.6953\n",
      "Test - Loss: 0.0527 Acc: 0.5430\n",
      "Epoch 14 over 50\n",
      "Train - Loss: 0.0166 Acc: 0.7275\n",
      "Test - Loss: 0.0523 Acc: 0.5643\n",
      "Epoch 15 over 50\n",
      "Train - Loss: 0.0149 Acc: 0.7512\n",
      "Test - Loss: 0.0543 Acc: 0.5572\n",
      "Epoch 16 over 50\n",
      "Train - Loss: 0.0134 Acc: 0.7642\n",
      "Test - Loss: 0.0526 Acc: 0.5816\n",
      "Epoch 17 over 50\n",
      "Train - Loss: 0.0125 Acc: 0.7822\n",
      "Test - Loss: 0.0523 Acc: 0.5719\n",
      "Epoch 18 over 50\n",
      "Train - Loss: 0.0113 Acc: 0.7992\n",
      "Test - Loss: 0.0531 Acc: 0.5958\n",
      "Epoch 19 over 50\n",
      "Train - Loss: 0.0105 Acc: 0.8099\n",
      "Test - Loss: 0.0537 Acc: 0.5831\n",
      "Epoch 20 over 50\n",
      "Train - Loss: 0.0096 Acc: 0.8176\n",
      "Test - Loss: 0.0561 Acc: 0.5872\n",
      "Epoch 21 over 50\n",
      "Train - Loss: 0.0091 Acc: 0.8196\n",
      "Test - Loss: 0.0549 Acc: 0.5877\n",
      "Epoch 22 over 50\n",
      "Train - Loss: 0.0086 Acc: 0.8329\n",
      "Test - Loss: 0.0568 Acc: 0.6029\n",
      "Epoch 23 over 50\n",
      "Train - Loss: 0.0080 Acc: 0.8432\n",
      "Test - Loss: 0.0568 Acc: 0.5948\n",
      "Epoch 24 over 50\n",
      "Train - Loss: 0.0074 Acc: 0.8554\n",
      "Test - Loss: 0.0573 Acc: 0.6065\n",
      "Epoch 25 over 50\n",
      "Train - Loss: 0.0069 Acc: 0.8607\n",
      "Test - Loss: 0.0576 Acc: 0.6004\n",
      "Epoch 26 over 50\n",
      "Train - Loss: 0.0070 Acc: 0.8573\n",
      "Test - Loss: 0.0602 Acc: 0.5948\n",
      "Epoch 27 over 50\n",
      "Train - Loss: 0.0067 Acc: 0.8700\n",
      "Test - Loss: 0.0561 Acc: 0.6126\n",
      "Epoch 28 over 50\n",
      "Train - Loss: 0.0061 Acc: 0.8797\n",
      "Test - Loss: 0.0599 Acc: 0.6136\n",
      "Epoch 29 over 50\n",
      "Train - Loss: 0.0058 Acc: 0.8854\n",
      "Test - Loss: 0.0589 Acc: 0.6182\n",
      "Epoch 30 over 50\n",
      "Train - Loss: 0.0054 Acc: 0.8941\n",
      "Test - Loss: 0.0584 Acc: 0.6258\n",
      "Epoch 31 over 50\n",
      "Train - Loss: 0.0053 Acc: 0.8903\n",
      "Test - Loss: 0.0595 Acc: 0.6228\n",
      "Epoch 32 over 50\n",
      "Train - Loss: 0.0052 Acc: 0.8979\n",
      "Test - Loss: 0.0627 Acc: 0.5872\n",
      "Epoch 33 over 50\n",
      "Train - Loss: 0.0050 Acc: 0.8967\n",
      "Test - Loss: 0.0635 Acc: 0.6192\n",
      "Epoch 34 over 50\n",
      "Train - Loss: 0.0049 Acc: 0.9014\n",
      "Test - Loss: 0.0632 Acc: 0.6197\n",
      "Epoch 35 over 50\n",
      "Train - Loss: 0.0048 Acc: 0.9016\n",
      "Test - Loss: 0.0615 Acc: 0.6182\n",
      "Epoch 36 over 50\n",
      "Train - Loss: 0.0044 Acc: 0.9111\n",
      "Test - Loss: 0.0643 Acc: 0.6055\n",
      "Epoch 37 over 50\n",
      "Train - Loss: 0.0046 Acc: 0.9085\n",
      "Test - Loss: 0.0608 Acc: 0.6238\n",
      "Epoch 38 over 50\n",
      "Train - Loss: 0.0044 Acc: 0.9096\n",
      "Test - Loss: 0.0597 Acc: 0.6268\n",
      "Epoch 39 over 50\n",
      "Train - Loss: 0.0042 Acc: 0.9150\n",
      "Test - Loss: 0.0629 Acc: 0.6274\n",
      "Epoch 40 over 50\n",
      "Train - Loss: 0.0040 Acc: 0.9198\n",
      "Test - Loss: 0.0641 Acc: 0.6238\n",
      "Epoch 41 over 50\n",
      "Train - Loss: 0.0039 Acc: 0.9196\n",
      "Test - Loss: 0.0665 Acc: 0.6218\n",
      "Epoch 42 over 50\n",
      "Train - Loss: 0.0038 Acc: 0.9226\n",
      "Test - Loss: 0.0652 Acc: 0.6243\n",
      "Epoch 43 over 50\n",
      "Train - Loss: 0.0035 Acc: 0.9275\n",
      "Test - Loss: 0.0682 Acc: 0.6268\n",
      "Epoch 44 over 50\n",
      "Train - Loss: 0.0038 Acc: 0.9185\n",
      "Test - Loss: 0.0675 Acc: 0.6243\n",
      "Epoch 45 over 50\n",
      "Train - Loss: 0.0038 Acc: 0.9170\n",
      "Test - Loss: 0.0658 Acc: 0.6304\n",
      "Epoch 46 over 50\n",
      "Train - Loss: 0.0034 Acc: 0.9287\n",
      "Test - Loss: 0.0658 Acc: 0.6207\n",
      "Epoch 47 over 50\n",
      "Train - Loss: 0.0037 Acc: 0.9209\n",
      "Test - Loss: 0.0643 Acc: 0.6162\n",
      "Epoch 48 over 50\n",
      "Train - Loss: 0.0035 Acc: 0.9279\n",
      "Test - Loss: 0.0656 Acc: 0.6426\n",
      "Epoch 49 over 50\n",
      "Train - Loss: 0.0032 Acc: 0.9344\n",
      "Test - Loss: 0.0677 Acc: 0.6314\n",
      "Epoch 50 over 50\n",
      "Train - Loss: 0.0030 Acc: 0.9352\n",
      "Test - Loss: 0.0675 Acc: 0.6223\n",
      "Test - Loss: 0.0672 Acc: 0.6324\n",
      "Real class: LACHNOCLOSTRIDIUM\n",
      "0.831 -> LACHNOSPIRACEAE_GENUS\n",
      "0.082 -> ROBINSONIELLA\n",
      "Real class: ALKALIPHILUS\n",
      "0.999 -> ALKALIPHILUS\n",
      "0.000 -> ANAEROVIRGULA\n",
      "Real class: LACHNOSPIRACEAE_NK4A136_GROUP\n",
      "0.891 -> LACHNOSPIRACEAE_GENUS\n",
      "0.086 -> LACHNOSPIRACEAE_AC2044_GROUP\n",
      "Real class: RUMINICLOSTRIDIUM\n",
      "1.000 -> RUMINICLOSTRIDIUM\n",
      "0.000 -> RUMINOCOCCACEAE_GENUS\n",
      "Real class: STREPTOCOCCUS\n",
      "0.600 -> BACTEROIDES\n",
      "0.275 -> LACTOCOCCUS\n",
      "Real class: ACINETOBACTER\n",
      "1.000 -> ACINETOBACTER\n",
      "0.000 -> ALKANINDIGES\n",
      "Real class: SPOROSALIBACTERIUM\n",
      "0.649 -> SOLOBACTERIUM\n",
      "0.063 -> ALKALIPHILUS\n",
      "Real class: GEMMATIMONAS\n",
      "0.977 -> GEMMATIMONAS\n",
      "0.023 -> GEMMATIMONADETES_GENUS\n",
      "Real class: GASTRANAEROPHILALES_GENUS\n",
      "0.349 -> GASTRANAEROPHILALES_GENUS\n",
      "0.283 -> LACHNOSPIRACEAE_GENUS\n",
      "Real class: PAPILLIBACTER\n",
      "0.833 -> BUTYRICICOCCUS\n",
      "0.143 -> RUMINOCOCCACEAE_GENUS\n",
      "Real class: SACCHAROPOLYSPORA\n",
      "0.634 -> SACCHAROTHRIX\n",
      "0.277 -> ACTINOKINEOSPORA\n",
      "Real class: ENTEROCOCCUS\n",
      "0.993 -> ENTEROCOCCUS\n",
      "0.003 -> MELISSOCOCCUS\n",
      "Real class: EUBACTERIUM\n",
      "0.783 -> EUBACTERIUM\n",
      "0.186 -> [EUBACTERIUM]_SAPHENUM_GROUP\n",
      "Real class: [EUBACTERIUM]_VENTRIOSUM_GROUP\n",
      "0.455 -> LACHNOCLOSTRIDIUM\n",
      "0.438 -> LACHNOSPIRACEAE_GENUS\n",
      "Real class: BIFIDOBACTERIUM\n",
      "0.986 -> BIFIDOBACTERIUM\n",
      "0.005 -> MOLLICUTES_NB1-N_GENUS\n",
      "Real class: DELTAPROTEOBACTERIA_GENUS\n",
      "0.443 -> ALGIMONAS\n",
      "0.257 -> RUMINOCOCCACEAE_GENUS\n",
      "Real class: DIPLORICKETTSIA\n",
      "1.000 -> DIPLORICKETTSIA\n",
      "0.000 -> COXIELLACEAE_GENUS\n",
      "Real class: PARAFILIMONAS\n",
      "0.273 -> BACTEROIDETES_VC2.1_BAC22_GENUS\n",
      "0.215 -> LACHNOSPIRACEAE_GENUS\n",
      "Real class: THIOPROFUNDUM\n",
      "0.761 -> ECTOTHIORHODOSPIRACEAE_GENUS\n",
      "0.165 -> THIOPROFUNDUM\n",
      "Real class: ARMATIMONAS\n",
      "0.727 -> ARMATIMONAS\n",
      "0.096 -> RHODOVASTUM\n"
     ]
    }
   ],
   "source": [
    "for parameter_config in parameter_config_list:\n",
    "    dim = parameter_config['dimension']\n",
    "    k_mer = parameter_config['k_mer']\n",
    "    max_size = parameter_config['vector_max_size']\n",
    "    file_path = 'results/models/CNN {}D - V_ACM - CNN({}) - accuracies.csv'.format(\n",
    "        dim, k_mer\n",
    "    )\n",
    "    print('Working with the following parameter configuration: \\n {}'.format(parameter_config))\n",
    "    train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=parameter_config['sequence_origin'], \n",
    "        primers_origin=parameter_config['primers_origin'],\n",
    "        selected_primer=parameter_config['selected_primer'], \n",
    "        taxonomy_level=parameter_config['taxonomy_level'],\n",
    "        max_size=max_size,\n",
    "        k_mer=k_mer\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin=parameter_config['sequence_origin'], \n",
    "                                                               primers_origin=parameter_config['primers_origin'], \n",
    "                                                               selected_primer=parameter_config['selected_primer'], \n",
    "                                                               taxonomy_level=parameter_config['taxonomy_level'])\n",
    "    n_out_features = len(dict_class_to_id)\n",
    "\n",
    "    n_epochs = parameter_config['n_epochs']\n",
    "\n",
    "    conv_class = classifier_GD_2_ACM(n_out_features, parameter_config)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate = parameter_config['learning_rate']\n",
    "    optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
    "\n",
    "    _, _, _, _ = test(conv_class, test_loader, loss_fn)\n",
    "    begin_time = time.time()\n",
    "    loss_train, acc_train, loss_test, acc_test = train(conv_class, train_loader, test_loader, loss_fn, optimizer_cl, n_epochs=n_epochs)\n",
    "    end_time = time.time()\n",
    "    final_test_loss, accuracy, y_test_torch, y_pred_torch = test(conv_class, test_loader, loss_fn)\n",
    "    \n",
    "    parameter_config['accuracy'] = accuracy\n",
    "    parameter_config['training_time'] = end_time - begin_time\n",
    "    \n",
    "    main_cnn_stats_model(y_train, y_test_torch, y_pred_torch, dict_id_to_class, loss_train, loss_test, acc_train, acc_test,\n",
    "                     make_plot=True,\n",
    "                     save_model=True,\n",
    "                     parameter_config=parameter_config,\n",
    "                     create_acm=True,\n",
    "                     acm_parameters=[X_test, y_test, 20],\n",
    "                     model_name='CNN - V_ACM - {}D'.format(dim),\n",
    "                     model_class=conv_class,\n",
    "                     model_preprocessing='OHE of letters in {} dimensions (k={}) - max size = {}'.format(4**k_mer, k_mer, max_size),\n",
    "                     sequence_origin=parameter_config['sequence_origin'],\n",
    "                     primers_origin=parameter_config['primers_origin'],\n",
    "                     taxonomy_level=parameter_config['taxonomy_level'],\n",
    "                     selected_primer=parameter_config['selected_primer'])\n",
    "    \n",
    "    save_update_cnn(file_path, parameter_config.keys(), parameter_config.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTIVATION MAP Manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from models.cnn_acm import create_activation_map\n",
    "from models.loading_model_data import main_loading_model_data\n",
    "from models.cnn_preprocessing import main_preprocessing_cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter_config = {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'sequence', 'taxonomy_level':1, 'dimension':2, 'k_mer':1, 'vector_max_size':1500, 'out_channel_1':64, 'out_channel_2':64, 'kernel_size_1_W':10, 'kernel_size_2_W':10, 'max_pool_stride_1_W':10, 'max_pool_stride_2_W':10, 'n_epochs':50, 'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_size = parameter_config['vector_max_size']\n",
    "k_mer = parameter_config['k_mer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = main_loading_model_data(sequence_origin=parameter_config['sequence_origin'], \n",
    "                                                               primers_origin=parameter_config['primers_origin'], \n",
    "                                                               selected_primer=parameter_config['selected_primer'], \n",
    "                                                               taxonomy_level=parameter_config['taxonomy_level'])\n",
    "train_loader, test_loader, dict_class_to_id, dict_id_to_class = main_preprocessing_cnn(\n",
    "        sequence_origin=parameter_config['sequence_origin'], \n",
    "        primers_origin=parameter_config['primers_origin'],\n",
    "        selected_primer=parameter_config['selected_primer'], \n",
    "        taxonomy_level=parameter_config['taxonomy_level'],\n",
    "        max_size=max_size,\n",
    "        k_mer=k_mer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis_path = 'D:\\\\0 - Boulot\\\\5 - X4\\\\16. Research Paper\\\\model_results\\\\CNN - V_ACM - 2D\\\\00021_analysis_sequence_1\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_activation_map(X_test, y_test, dict_id_to_class, parameter_config, n=3, analysis_path=analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model structure image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from models.cnn_model import classifier_GD_2_ACM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_out_features = 44\n",
    "parameter_config = {'sequence_origin':'DairyDB', 'primers_origin':'DairyDB', 'selected_primer':'V4', 'taxonomy_level':1, 'dimension':2, 'k_mer':1, 'vector_max_size':300, 'out_channel_1':128, 'out_channel_2':128, 'kernel_size_1_W':14, 'kernel_size_2_W':14, 'max_pool_stride_1_W':6, 'max_pool_stride_2_W':6, 'n_epochs':30, 'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_class = classifier_GD_2_ACM(n_out_features, parameter_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = torch.randn(1, 4, 300).requires_grad_(True)\n",
    "y = conv_class(x)\n",
    "make_dot(y, params=dict(list(conv_class.named_parameters()) + [('x', x)])).render(\"attached\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
